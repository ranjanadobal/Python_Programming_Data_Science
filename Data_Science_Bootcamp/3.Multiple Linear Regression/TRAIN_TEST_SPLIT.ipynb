{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#In this lesson we will explore the train_test_split module\n",
    "#Therefore we need no more than the module itself and NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Underfitting means the model has not captured the underlying logic of the data, it doesn't have strong predictive power.Underfitted models are clumsy and have a low accuracy. Either there are no relationships to be found, or we need a different model.It has low train accuracy and low test accuracy. \n",
    "\n",
    "Underfitting is easy to spot. You have almost no accuracy whatsoever. Overfitting is much harder, though, as the accuracy of the model seems outstanding.\n",
    "Overfitting means our regression has focused on the particular data set so much it has missed the point. Overfitting refers to models that are so super good at modeling the data that they fit, or at least come very near each observation. The problem is that the random noise is captured inside an overfitted model.It has high train accuracy and low test accuracy. \n",
    "\n",
    "One solution to overfitting is to split our initial data set into two, training and test. Splits like 90% training and 10% test, or 80 20 are common. We create the regression on the training data. After we have the coefficients, we test the model on the test data by assessing the accuracy. The whole point is that the model has never seen the test data set. Therefore, it cannot overfit on it. We are trying to avoid the scenario where the model learns to predict the training data very well but fails miserably when given new samples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate some data we are going to split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Let's generate a new data frame 'a' which will contain all integers from 1 to 100\n",
    "#The method np.arange works like the built-in method 'range' with the difference that it creates an array instead of a list. The array contains values from 1 to 100 included. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(1,101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Let's check it out. It is very important that the values inside are arranged in order to follow\n",
    "what the splitting process has accomplished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Similarly, let's create another ndarray 'b', which will contain integers from 501 to 600\n",
    "#We have intentionally picked these numbers so we can easily compare the two.\n",
    "The difference between the elements of the two arrays is 500 for any two corresponding elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513,\n",
       "       514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526,\n",
       "       527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539,\n",
       "       540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552,\n",
       "       553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565,\n",
       "       566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578,\n",
       "       579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591,\n",
       "       592, 593, 594, 595, 596, 597, 598, 599, 600])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.arange(501,601)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Train_test_split works by taking an array and spliting it into two arrays. Let's check out how this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 33,   8,   5,  92,  31,  85,  29,  60,  12,  80,  99,   4,  17,\n",
       "         81,  25,  63,   7,  11,  18,   3,  32,  16,  21,  55,  67,  40,\n",
       "        100,  34,  14,  78,  50,  89,  57,  42,  28,  58,  51,  53,  37,\n",
       "         86,  54,  98,  22,  19,  74,  20,  82,   2,  24,  44,  87,  56,\n",
       "          9,  93,  70,  10,  68,  65,  23,  30,  13,  48,  47,  27,  91,\n",
       "         36,  88,  43,  83,  59,  75,  94,  66,  73,  49]),\n",
       " array([45, 71, 96, 84,  1, 90, 77, 46, 38,  6, 26, 39, 72, 69, 79, 35, 76,\n",
       "        97, 95, 61, 64, 41, 62, 52, 15])]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#We would prefer storing the result in dedicated variables so we can write a_train, a_test equals train_test_split of a. The first array is always considered to be the training array while the second, the testing one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_train, a_test = train_test_split(a) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#First, let's check the shapes of the two variables. a_train has a length of 75 while a_test, a length of 25. This means that default split is 75,25. Both arrays are also shuffled after train test split. Earlier, they were numbers ordered from 1 to 100 but now they are completely randomized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75,), (25,))"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_train.shape, a_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 63,  21,  46,  12,  68,  13,  71,  26,  96,  75,  99,  18,  72,\n",
       "        91,  38,  36,   1,  77,  57,  55,  30,   3,   7,  88,  39,  60,\n",
       "        74,  95,  27,  97,  28,  11,  19,  79,  25,   6,  33,  93,  78,\n",
       "        14,  29,  50,   4, 100,  66,  58,  48,  15,  84,  41,  87,  65,\n",
       "        34,  73,  37,  85,  17,  45,  52,  81,  42,  62,  35,  69,  82,\n",
       "        70,  31,  54,  98,  92,   9,  51,  94,  23,  44])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24, 86, 76,  8, 47, 16, 83, 53, 64, 22, 90, 56, 32, 43, 49, 40, 59,\n",
       "       61, 20, 89,  2, 10,  5, 67, 80])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##75-25 split are the default settings of train_test_split. 75, 25 might dedicate too much data to testing. To change this, we can use an argument called test size and set it to a float between zero and one. Therefore, to achieve an 80/20 split, we need to simply include test_size equals 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_train, a_test = train_test_split(a, test_size = 0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80,), (20,))"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_train.shape, a_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([52, 10, 44, 19, 75,  1, 69, 78, 50, 22, 84, 95, 62, 73, 63, 39,  8,\n",
       "       24, 80, 97,  3, 83, 26, 54, 87, 68, 23, 20, 47,  6, 51, 18, 71, 72,\n",
       "       42, 56, 12, 92, 74, 40, 17, 96, 28, 13,  4, 61, 48, 31, 91, 16, 99,\n",
       "       94, 82, 30, 86, 34, 76, 29, 32, 43, 98, 53, 41, 37, 35, 14, 65, 25,\n",
       "       79, 46, 55, 88,  5, 89, 77, 11, 58,  7, 59, 67])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100,  27,  36,  85,  90,  33,  60,  21,  93,  38,  45,  70,  64,\n",
       "        49,  66,  81,   9,  57,  15,   2])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#There's an argument called shuffle which is set to true by default. Changing that to false would place the first 80 observations of a in a_train while the last 20 in a_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_train, a_test = train_test_split(a, test_size = 0.2, shuffle = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
       "        94,  95,  96,  97,  98,  99, 100])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Most of the time, we prefer to shuffle the data. This removes time dependencies, day of the week effects. Let's remove the shuffle argument to get randomized values in a_train and a_test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_train, a_test = train_test_split(a, test_size = 0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 17, 73, 93, 39, 77, 19, 68, 91, 12, 78, 49, 13, 25, 54, 96, 22,\n",
       "       94, 63, 33,  8, 16, 34, 31, 60, 84,  1, 65, 23, 52, 89, 15, 10, 24,\n",
       "       56,  3, 11, 29, 32, 44,  4, 43, 21, 14, 30, 99, 88, 62, 51, 72, 86,\n",
       "       58, 42, 70, 45, 67, 66, 85,  2, 59, 81, 38, 98,  7, 46, 95, 18, 53,\n",
       "       80, 57, 48, 64,  9, 74, 47, 92, 28, 97, 35, 36])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 40,  75,  41,  82, 100,  37,  71,  27,  55,  69,  90,  26,  20,\n",
       "        50,  87,  79,  61,   5,  83,  76])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Each time we run the code, we get a different shuffle. So the data is rearranged in a random manner. This could be an issue for modeling. Each time we split the data, we will get different training and testing datasets and we'd be creating a different regression on different data each time we run the cells. Training a model on different training data would generally have little impact,but it will have some impact. The R squared is likely to change with one or two percentage points just because of the split. If we are trying to improve the model with many tiny tweaks, each of which are bringing 1 or 2% of additional explanatory power, a different shuffle every time would prevent an objective assessment of the changes. In the best case scenario, we would like to have shuffle data but shuffled in the same way every time. For that, Sklearn has a random state argument. We'll add the random state argument and set it to 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_train, a_test = train_test_split(a, test_size = 0.2, random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 56,  89,  27,  43,  70,  16,  41,  97,  10,  73,  12,  48,  86,\n",
       "        29,  94,   6,  67,  66,  36,  17,  50,  35,   8,  96,  28,  20,\n",
       "        82,  26,  63,  14,  25,   4,  18,  39,   9,  79,   7,  65,  37,\n",
       "        90,  57, 100,  55,  44,  51,  68,  47,  69,  62,  98,  80,  42,\n",
       "        59,  49,  99,  58,  76,  33,  95,  60,  64,  85,  38,  30,   2,\n",
       "        53,  22,   3,  24,  88,  92,  75,  87,  83,  21,  61,  72,  15,\n",
       "        93,  52])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([84, 54, 71, 46, 45, 40, 23, 81, 11,  1, 19, 31, 74, 34, 91,  5, 77,\n",
       "       78, 13, 32])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#If we try rerunning the code again and again, we would always get the exact same shuffled split. If we want to get a different shuffled split, we would simply change the random state to a different number like 365."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_train, a_test = train_test_split(a, test_size = 0.2, random_state = 365) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 25,  32,  99,  73,  91,  66,   3,  59,  94,   1,   8,  15,  90,\n",
       "        54,  31,  20,  77,  82,  30,  35,  95,  42,  38,   7,  11,  50,\n",
       "        21,  48,   2,  17,  10,  58,  68,  43,  41,  16,  88,  72,  79,\n",
       "       100,  80,  39,  24,  86,  22,  23,  62,  76,  18,  47,  55,  26,\n",
       "        60,  19,  71,  64,  51,  63,  65,  28,  12,  78,  13,  44,  75,\n",
       "        87,  40,   4,  29,  49,  37,  57,  27,  74,   6,  45,  92,  34,\n",
       "        53,  83])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 69, 81, 56, 33, 93, 84, 61, 46, 89, 85, 67, 97,  5, 70, 36, 98,\n",
       "       96, 14, 52])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#We got a different shuffled split and no matter how many times we rerun the cells, the split doesn't change while the numbers are still randomized. This also allows us to split more than one array at the same time. We can simply add b as an argument and include two new variables to store the returned arrays. We'll call them b_train and b_test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#There are several different arguments we can set when we employ this method\n",
    "#Most often, we have inputs and targets, so we have to split 2 different arrays\n",
    "#we are simulating this situation by splitting 'a' and 'b'\n",
    "\n",
    "\n",
    "#We can specify the 'test_size'. Common splits are 75-25, 80-20, 85-15, 90-10. Finally, we should always employ a 'random_state'. In this way we ensure that when we are splitting the data we will always get the SAME random shuffle\n",
    "\n",
    "#Note that 2 arrays will be split into 4. The order is train1, test1, train2, test2. It is very useful to store them in 4 variables, so we can later use them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_train, a_test, b_train, b_test = train_test_split(a, b, test_size=0.2, random_state=365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Let's check the shapes\n",
    "#Basically, we are checking how does the 'test_size' work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80,), (20,))"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_train.shape, a_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Explore manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 25,  32,  99,  73,  91,  66,   3,  59,  94,   1,   8,  15,  90,\n",
       "        54,  31,  20,  77,  82,  30,  35,  95,  42,  38,   7,  11,  50,\n",
       "        21,  48,   2,  17,  10,  58,  68,  43,  41,  16,  88,  72,  79,\n",
       "       100,  80,  39,  24,  86,  22,  23,  62,  76,  18,  47,  55,  26,\n",
       "        60,  19,  71,  64,  51,  63,  65,  28,  12,  78,  13,  44,  75,\n",
       "        87,  40,   4,  29,  49,  37,  57,  27,  74,   6,  45,  92,  34,\n",
       "        53,  83])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Explore manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 69, 81, 56, 33, 93, 84, 61, 46, 89, 85, 67, 97,  5, 70, 36, 98,\n",
       "       96, 14, 52])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80,), (20,))"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_train.shape, b_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([525, 532, 599, 573, 591, 566, 503, 559, 594, 501, 508, 515, 590,\n",
       "       554, 531, 520, 577, 582, 530, 535, 595, 542, 538, 507, 511, 550,\n",
       "       521, 548, 502, 517, 510, 558, 568, 543, 541, 516, 588, 572, 579,\n",
       "       600, 580, 539, 524, 586, 522, 523, 562, 576, 518, 547, 555, 526,\n",
       "       560, 519, 571, 564, 551, 563, 565, 528, 512, 578, 513, 544, 575,\n",
       "       587, 540, 504, 529, 549, 537, 557, 527, 574, 506, 545, 592, 534,\n",
       "       553, 583])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([509, 569, 581, 556, 533, 593, 584, 561, 546, 589, 585, 567, 597,\n",
       "       505, 570, 536, 598, 596, 514, 552])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#a consists of the ordered sequence of the numbers from 1 to a 100 while b from 501 to 600. We can say that the number 1 from a matches with 501 from B, 25 from A matches with 525 from B and so on. This is extremely important for regressions because we want a certain observation's inputs to match with its target even after shuffling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
