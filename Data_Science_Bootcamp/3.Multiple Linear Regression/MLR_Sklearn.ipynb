{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f340be39",
   "metadata": {},
   "source": [
    "# Multiple linear regression and adjusted R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf4c37",
   "metadata": {},
   "source": [
    "## Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "40d72756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn\n",
    "seaborn.set()\n",
    "\n",
    "# the actual regression (machine learning) module\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674d3247",
   "metadata": {},
   "source": [
    "## Load the data from a .csv in the same folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "57c861be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/ranjanadobal/Documents/data/MultipleLR/1.02. Multiple linear regression.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fd6f58",
   "metadata": {},
   "source": [
    "### Let's check what's inside this data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "75a33cf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Rand 1,2,3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1714</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1664</td>\n",
       "      <td>2.52</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1760</td>\n",
       "      <td>2.54</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1685</td>\n",
       "      <td>2.74</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1693</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SAT   GPA  Rand 1,2,3\n",
       "0  1714  2.40           1\n",
       "1  1664  2.52           3\n",
       "2  1760  2.54           3\n",
       "3  1685  2.74           3\n",
       "4  1693  2.83           2"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ba3fed",
   "metadata": {},
   "source": [
    "#There are two input features, SAT score and Rand 1,2,3 and the dependent variable is GPA.Rand1,2,3 is a variable which randomly assigns 1,2,3 to each sample. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ccf20a",
   "metadata": {},
   "source": [
    "### Print the descriptive statistics for each column in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "b9aa5138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Rand 1,2,3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1845.273810</td>\n",
       "      <td>3.330238</td>\n",
       "      <td>2.059524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.530661</td>\n",
       "      <td>0.271617</td>\n",
       "      <td>0.855192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1634.000000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1772.000000</td>\n",
       "      <td>3.190000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1846.000000</td>\n",
       "      <td>3.380000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1934.000000</td>\n",
       "      <td>3.502500</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2050.000000</td>\n",
       "      <td>3.810000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SAT        GPA  Rand 1,2,3\n",
       "count    84.000000  84.000000   84.000000\n",
       "mean   1845.273810   3.330238    2.059524\n",
       "std     104.530661   0.271617    0.855192\n",
       "min    1634.000000   2.400000    1.000000\n",
       "25%    1772.000000   3.190000    1.000000\n",
       "50%    1846.000000   3.380000    2.000000\n",
       "75%    1934.000000   3.502500    3.000000\n",
       "max    2050.000000   3.810000    3.000000"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae80130c",
   "metadata": {},
   "source": [
    "## Multiple Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1913b1",
   "metadata": {},
   "source": [
    "### Declare the dependent and independent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b01854",
   "metadata": {},
   "source": [
    "#There are two independent variables: 'SAT' and 'Rand 1,2,3' and a single depended variable: 'GPA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "533c67c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[['SAT','Rand 1,2,3']]\n",
    "\n",
    "y = data['GPA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4415bd03",
   "metadata": {},
   "source": [
    "### Regression itself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b0809e",
   "metadata": {},
   "source": [
    "#We start by creating a linear regression object and then we fit the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "dd926b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "\n",
    "reg.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9d1893",
   "metadata": {},
   "source": [
    "#Getting the coefficients of the regression. The output is an array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "15a5a19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00165354, -0.00826982])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff84cef6",
   "metadata": {},
   "source": [
    "#The coefficients are ordered in the way they were fed in the model. 0.0017 is the coefficient for SAT and -0.0083 is the coefficient for Rand1,2,3.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24d5baf",
   "metadata": {},
   "source": [
    "#Getting the intercept of the regression. The result is a float as we usually expect a single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "5c616aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29603261264909486"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f09d18",
   "metadata": {},
   "source": [
    "#The intercept of the model is 0.296. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3c2c9f",
   "metadata": {},
   "source": [
    "### Calculating the R-squared. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8681544d",
   "metadata": {},
   "source": [
    "#Get the R-squared of the regression. R-squared is the most common measures of goodness of fit. The same score() method can be used for both simple linear regression and multiple linear regression. Score method takes two arguments - inputs and target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "21bf29ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40668119528142843"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd5225d",
   "metadata": {},
   "source": [
    "#The R-squared value is exactly the same as the statsmodels summary. Ajd R-squared is a more appropriate measure for multiple linear regression. There is no method in sklearn to calculate Adj R-squared directly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2af2bd4",
   "metadata": {},
   "source": [
    "### Formula for Adjusted R^2\n",
    "\n",
    "$R^2_{adj.} = 1 - (1-R^2)*\\frac{n-1}{n-p-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef975145",
   "metadata": {},
   "source": [
    "#In this formula, N is the number of observations i.e. 84 and p is the number of predictors i.e. 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a894c586",
   "metadata": {},
   "source": [
    "#Get the shape of x, to facilitate the creation of the Adjusted R^2 metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "72787b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 2)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0dff8a",
   "metadata": {},
   "source": [
    "#If we want to find the Adjusted R-squared we can do so by knowing the r2, the # observations, the # features.  \n",
    "Number of observations is the shape along axis 0. \n",
    "Number of features (predictors, p) is the shape along axis 1. \n",
    "We find the Adjusted R-squared using the formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "849c5491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39203134825134023"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = reg.score(x,y)\n",
    "\n",
    "n = x.shape[0]\n",
    "\n",
    "p = x.shape[1]\n",
    "\n",
    "\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "adjusted_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be8c6c",
   "metadata": {},
   "source": [
    "#The Adj R-squared is  0.392 which is lesser than R-squared 0.407 and this means one of the predictors has very little explanatory power. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1b7e0c",
   "metadata": {},
   "source": [
    "## Feature selection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf66f6fa",
   "metadata": {},
   "source": [
    "#Feature Selection is a process created to detect the variables which are not needed in a model. \n",
    "#Import the feature selection module from sklearn\n",
    "#This module allows us to select the most appopriate features for our regression\n",
    "#There exist many different approaches to feature selection, however, this is one of the simplest.\n",
    "\n",
    "This process helps improve speed and prevents other issues due to too many features. This process uses the p-values of variables and discards the variables with p-value above 0.05. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b01114be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804cdd6b",
   "metadata": {},
   "source": [
    "#We will look into: f_regression\n",
    "#f_regression finds the F-statistics for the *simple* regressions created with each of the independent variables\n",
    "#In our case, this would mean running a simple linear regression on GPA where SAT is the independent variable\n",
    "#and a simple linear regression on GPA where Rand 1,2,3 is the indepdent variable\n",
    "#The limitation of this approach is that it does not take into account the mutual effect of the two features.\n",
    "Call the method f_regression with arguments the features contained in X and the target contained in Y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "cf414f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([56.04804786,  0.17558437]), array([7.19951844e-11, 6.76291372e-01]))"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_regression(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ea0ab3",
   "metadata": {},
   "source": [
    "#There are two output arrays\n",
    "#The first one contains the F-statistics for each of the regressions\n",
    "#The second one contains the p-values of these F-statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27401718",
   "metadata": {},
   "source": [
    "#Since we are more interested in the latter (p-values), we can just take the second and store it in a new variable 'p-values'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "5fee0179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.19951844e-11, 6.76291372e-01])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values = f_regression(x,y)[1]\n",
    "p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ad9334",
   "metadata": {},
   "source": [
    "#e-11 means multiplied by 10 to the power -11. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3994a844",
   "metadata": {},
   "source": [
    "#To be able to quickly evaluate them, we can round the result to 3 digits after the dot.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "89b0785d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.676])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2e4c5b",
   "metadata": {},
   "source": [
    "#The p-value of the first column SAT is 0.000 and the p-value of the second column Rand1,2,3 is 0.676. Rand1,2,3 variable is not significant in the model. These p-values do not reflect the interconnection of these variables in the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4505634a",
   "metadata": {},
   "source": [
    "## Creating a summary table "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49efaeba",
   "metadata": {},
   "source": [
    "#Let's create a new data frame with the names of the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "f8cde828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rand 1,2,3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features\n",
       "0         SAT\n",
       "1  Rand 1,2,3"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_summary = pd.DataFrame(data = x.columns.values, columns=['Features'])\n",
    "reg_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba36248",
   "metadata": {},
   "source": [
    "#Then we create and fill a second column, called 'Coefficients' with the coefficients of the regression. # Finally, we add the p-values we just calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "bf51949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_summary ['Coefficients'] = reg.coef_\n",
    "reg_summary ['p-values'] = p_values.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c672c8",
   "metadata": {},
   "source": [
    "#Now we've got a pretty clean summary, which can help us make an informed decision about the inclusion of the variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "0e046a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coefficients</th>\n",
       "      <th>p-values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAT</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rand 1,2,3</td>\n",
       "      <td>-0.008270</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features  Coefficients  p-values\n",
       "0         SAT      0.001654     0.000\n",
       "1  Rand 1,2,3     -0.008270     0.676"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a6e741",
   "metadata": {},
   "source": [
    "The p-values help to determine if a variable is redundant, but they provide no information about how useful a variable is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ae750f",
   "metadata": {},
   "source": [
    "## Feature Scaling or standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e0aadf",
   "metadata": {},
   "source": [
    "#feature scaling is the process of transforming the data we are working with into a standard scale. This is achieved by subtracting the mean and dividing by the standard deviation. This way,regardless of the data set we will always obtain a distribution with a mean of zero and a standard deviation of one. \n",
    "\n",
    "#Import the preprocessing module StandardScaler from sklearn and is one of the easiest and 'cleanest' ways to preprocess your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "cfd77428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa07f50e",
   "metadata": {},
   "source": [
    "#Create a StandardScaler object which is empty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "2d46f5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "23309531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29b4986",
   "metadata": {},
   "source": [
    "#Fit the input data (x). Essentially, we are calculating the mean and standard deviation feature-wise (the mean of 'SAT' and the standard deviation of 'SAT', as well as the mean of 'Rand 1,2,3' and the standard deviation of 'Rand 1,2,3'). This line will calculate the mean and standard deviation of each feature. This information will be stored\n",
    "in the scaler object. This scaler object will now contain information about the mean and standard deviation of the data. Whenever we get new data,we know that the standardization information is contained in the scaler object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "12d3c716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e5c419",
   "metadata": {},
   "source": [
    "#The inputs are still unscaled. The actual scaling of the data is done through the method 'transform()'\n",
    "#Let's store it in a new variable x_scaled. transform() method transforms the unscaled inputs using the information contained in scaler and that means we subtract the mean and divide by the standard deviation for each feature. Whenever we get new data we will just apply scaler.transform new data to reach the same transformation as we just did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "8d56a6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e960e4",
   "metadata": {},
   "source": [
    "#The result is an ndarray and all the input data has been standardized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "7cc9cc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.26338288, -1.24637147],\n",
       "       [-1.74458431,  1.10632974],\n",
       "       [-0.82067757,  1.10632974],\n",
       "       [-1.54247971,  1.10632974],\n",
       "       [-1.46548748, -0.07002087],\n",
       "       [-1.68684014, -1.24637147],\n",
       "       [-0.78218146, -0.07002087],\n",
       "       [-0.78218146, -1.24637147],\n",
       "       [-0.51270866, -0.07002087],\n",
       "       [ 0.04548499,  1.10632974],\n",
       "       [-1.06127829,  1.10632974],\n",
       "       [-0.67631715, -0.07002087],\n",
       "       [-1.06127829, -1.24637147],\n",
       "       [-1.28263094,  1.10632974],\n",
       "       [-0.6955652 , -0.07002087],\n",
       "       [ 0.25721362, -0.07002087],\n",
       "       [-0.86879772,  1.10632974],\n",
       "       [-1.64834403, -0.07002087],\n",
       "       [-0.03150724,  1.10632974],\n",
       "       [-0.57045283,  1.10632974],\n",
       "       [-0.81105355,  1.10632974],\n",
       "       [-1.18639066,  1.10632974],\n",
       "       [-1.75420834,  1.10632974],\n",
       "       [-1.52323165, -1.24637147],\n",
       "       [ 1.23886453, -1.24637147],\n",
       "       [-0.18549169, -1.24637147],\n",
       "       [-0.5608288 , -1.24637147],\n",
       "       [-0.23361183,  1.10632974],\n",
       "       [ 1.68156984, -1.24637147],\n",
       "       [-0.4934606 , -0.07002087],\n",
       "       [-0.73406132, -1.24637147],\n",
       "       [ 0.85390339, -1.24637147],\n",
       "       [-0.67631715, -1.24637147],\n",
       "       [ 0.09360513,  1.10632974],\n",
       "       [ 0.33420585, -0.07002087],\n",
       "       [ 0.03586096, -0.07002087],\n",
       "       [-0.35872421,  1.10632974],\n",
       "       [ 1.04638396,  1.10632974],\n",
       "       [-0.65706909,  1.10632974],\n",
       "       [-0.13737155, -0.07002087],\n",
       "       [ 0.18984542,  1.10632974],\n",
       "       [ 0.04548499, -1.24637147],\n",
       "       [ 1.1618723 ,  1.10632974],\n",
       "       [-1.37887123, -1.24637147],\n",
       "       [ 1.39284898, -1.24637147],\n",
       "       [ 0.76728713, -0.07002087],\n",
       "       [-0.20473975, -0.07002087],\n",
       "       [ 1.06563201, -1.24637147],\n",
       "       [ 0.11285319, -1.24637147],\n",
       "       [ 1.28698467,  1.10632974],\n",
       "       [-0.41646838,  1.10632974],\n",
       "       [ 0.09360513, -1.24637147],\n",
       "       [ 0.59405462, -0.07002087],\n",
       "       [-2.03330517, -0.07002087],\n",
       "       [ 0.32458182, -1.24637147],\n",
       "       [ 0.40157405, -1.24637147],\n",
       "       [-1.10939843, -0.07002087],\n",
       "       [ 1.03675993, -1.24637147],\n",
       "       [-0.61857297, -0.07002087],\n",
       "       [ 0.44007016, -0.07002087],\n",
       "       [ 1.14262424, -1.24637147],\n",
       "       [-0.35872421,  1.10632974],\n",
       "       [ 0.45931822,  1.10632974],\n",
       "       [ 1.88367444,  1.10632974],\n",
       "       [ 0.45931822, -1.24637147],\n",
       "       [-0.12774752, -0.07002087],\n",
       "       [ 0.04548499,  1.10632974],\n",
       "       [ 0.85390339, -0.07002087],\n",
       "       [ 0.15134931, -0.07002087],\n",
       "       [ 0.8250313 ,  1.10632974],\n",
       "       [ 0.84427936,  1.10632974],\n",
       "       [-0.64744506, -1.24637147],\n",
       "       [ 1.24848856, -1.24637147],\n",
       "       [ 0.85390339,  1.10632974],\n",
       "       [ 1.69119387,  1.10632974],\n",
       "       [ 1.6334497 ,  1.10632974],\n",
       "       [ 1.46021718, -1.24637147],\n",
       "       [ 1.68156984, -0.07002087],\n",
       "       [-0.02188321,  1.10632974],\n",
       "       [ 0.87315144,  1.10632974],\n",
       "       [-0.33947615, -1.24637147],\n",
       "       [ 1.3639769 ,  1.10632974],\n",
       "       [ 1.12337618, -1.24637147],\n",
       "       [ 1.97029069, -0.07002087]])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23434ba6",
   "metadata": {},
   "source": [
    "## Regression with scaled features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa23f1b",
   "metadata": {},
   "source": [
    "In the earlier regression, the model was GPA = 0.296 + 0.0017SAT -0.0083Rand1,2,3 and by looking at the coefficients alone, it seems like Rand1,2,3 has a bigger coefficient and hence a greater impact.The SAT expression\n",
    "is contributing a lot more to the final expression overall, as 1800(SAT score) times 0.0017 equals 3.06, while two (Rand1,2,3) times minus 0.0083 equals 0.0166.\n",
    "This issue is overcome through feature scaling. Having all inputs with the same magnitude allows us to compare their impact.\n",
    "#Creating a regression works in the exact same way. # We just need to specify that our inputs are the 'scaled inputs' and specify the targets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "d87fb26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "\n",
    "\n",
    "reg.fit(x_scaled,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bee5324",
   "metadata": {},
   "source": [
    "#To look at the actual difference in regression, we can see the coefficients and intercept. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4cfaf8",
   "metadata": {},
   "source": [
    "#Let's see the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "897897ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.17181389, -0.00703007])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53fcbea",
   "metadata": {},
   "source": [
    "#And the intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "e5bad839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.330238095238095"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2ed14a",
   "metadata": {},
   "source": [
    "## Creating a summary table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aa0979",
   "metadata": {},
   "source": [
    "#As usual we can try to arrange the information in a summary table\n",
    "#Let's create a new data frame with the names of the features. \n",
    "#Then we create and fill a second column, called 'Weights' with the coefficients of the regression\n",
    "#Since the standardized coefficients are called 'weights' in ML, this is a much better word choice for our case\n",
    "#Note that even non-standardized coeff. are called 'weights' \n",
    "#but more often than not, when doing ML we perform some sort of scaling. The name 'weights' comes from the fact that the bigger the weight the bigger the impact of the feature on the regression. In a machine learning context, the intercept is called bias. The idea is that the intercept is nothing but a number which adjusts our regression with some constant. But if we need to adjust our regression with some constant then the regression is biased by that number.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "5dabe181",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_summary = pd.DataFrame([['Bias'],['SAT'],['Rand 1,2,3']], columns=['Features'])\n",
    "\n",
    "reg_summary['Weights'] = reg.intercept_, reg.coef_[0], reg.coef_[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aee016",
   "metadata": {},
   "source": [
    "#Now we have a pretty clean summary, which can help us make an informed decision about the importance of each feature. The closer a weight is to zero, the smaller it's impact. The bigger the weight,the bigger it's impact.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "b61cf150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bias</td>\n",
       "      <td>3.330238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SAT</td>\n",
       "      <td>0.171814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rand 1,2,3</td>\n",
       "      <td>-0.007030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features   Weights\n",
       "0        Bias  3.330238\n",
       "1         SAT  0.171814\n",
       "2  Rand 1,2,3 -0.007030"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ad6062",
   "metadata": {},
   "source": [
    "#This brings us to feature selection through standardization, we can clearly see that Rand 1,2, 3barely contributes to our outputs, if at all. It will make little difference if we remove it from the model or leave it there with a weight of almost zero.\n",
    "\n",
    "When we perform feature scaling, we don't really care if a useless variable is there or not. This is also one of the main reasons why Sklearn does not natively support P values. Since most ML practitioners perform some kindof feature scaling before fitting a model, we don't really need to identify the worst performing features. They are automatically penalized by having a very small weight.\n",
    "\n",
    "In general, it is better to leave out the worst performing features as they interact with the useful ones and may bias the weights even if only slightly so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c66a7d6",
   "metadata": {},
   "source": [
    "## Making predictions with the standardized coefficients (weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091f3050",
   "metadata": {},
   "source": [
    "#For simplicity, let's create a new dataframe with 2 *new* observations. One is a student who got 1700\n",
    "on the SAT and was assigned the number two randomly while the other had 1800 on the SAT and was assigned one randomly. The new dataframe should be arranged in the exact same way as our input data, X and must be standardized\n",
    "in the same way, with the same mean and standard deviation as we stored in the scaler object. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "3c8d12f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>Rand 1,2,3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1700</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SAT  Rand 1,2,3\n",
       "0  1700           2\n",
       "1  1800           1"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.DataFrame(data=[[1700,2],[1800,1]],columns=['SAT','Rand 1,2,3'])\n",
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0863be",
   "metadata": {},
   "source": [
    "#This is to ensure that the output is GPA because the regression model was trained on standardized inputs. We see that the predict method on the unscaled inputs gives an unexpected GPA output below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "a1491abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([295.39979563, 312.58821497])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.predict(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b009babb",
   "metadata": {},
   "source": [
    "##Our model is expecting SCALED features (features of different magnitude), so we must transform the 'new data' in the same way as we transformed the inputs we train the model on. This information is contained in the 'scaler' object. We simply transform the 'new data' using the relevant method. Let's scale the new_data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "b61d0b09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.39811928, -0.07002087],\n",
       "       [-0.43571643, -1.24637147]])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_scaled = scaler.transform(new_data)\n",
    "\n",
    "new_data_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b13a1f",
   "metadata": {},
   "source": [
    "#The result is an ND array which contains the standardized data. Now that looks exactly like the inputs we train the model with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd2c663",
   "metadata": {},
   "source": [
    "#We can make a prediction for a whole dataframe (not a single value) by calling the predict method on the regression\n",
    "and then specifying the new inputs as an argument.  Using the well-known method, predict we can find what the predictions are when we feed the new data scaled array. Here's the result, it is of the magnitude we anticipated.\n",
    "Our first student is predicted to have a GPAof 3.09 while the second 3.26."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7199b5",
   "metadata": {},
   "source": [
    "#Finally we make a prediction using the scaled new data and it gives an expected GPA output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "8edd8ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.09051403, 3.26413803])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.predict(new_data_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0564fde",
   "metadata": {},
   "source": [
    "#What if we removed the 'Random 1,2,3' variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9077ad4f",
   "metadata": {},
   "source": [
    "#Theory suggests that features with very small weights could be removed and the results should be identical\n",
    "#Moreover, we proved in 2-3 different ways that 'Rand 1,2,3' is an irrelevant feature\n",
    "#Let's create a simple linear regression (simple, because there is a single feature) without 'Rand 1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "54ecbe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_simple = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debcc802",
   "metadata": {},
   "source": [
    "#Once more, we must reshape the inputs into a matrix or a 2D array, otherwise we will get a compatibility error. #In order to feed x to sklearn, it should be a 2D array (a matrix).Therefore, we must reshape it. Note that we saw this in Simple Linear Regression that this is not needed when we've got more than 1 feature (as the inputs will be a 2D array by default). x_matrix = x.values.reshape(84,1). reshape(-1,1) is a more generalized approach. \n",
    "#Note that instead of standardizing again, I'll simply take only the first column of x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "75230a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_simple_matrix = x_scaled[:,0].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408fabc4",
   "metadata": {},
   "source": [
    "#Finally, we fit the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "15cbaf96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_simple.fit(x_simple_matrix,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee38816",
   "metadata": {},
   "source": [
    "#In a similar manner to the cell before, we can predict only the first column of the scaled 'new data'\n",
    "#Note that we also reshape it to be exactly the same as x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "7fef66e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.08970998, 3.25527879])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_simple.predict(new_data_scaled[:,0].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820037e9",
   "metadata": {},
   "source": [
    "#The predicted GPA is slightly different than what we received from or multiple linear regression earlier, but actually if we round up to two digits after the dot we get the exact same results 3.09 and 3.26. This finding shows us  that P values are not needed in sklearn. When we apply feature scaling it often does not affect the final result if We keep or leave out in significant features. Their weights will be so close to zero that they will barely influence the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef38425",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
